% A rule of thumb: at least 20 references, but no more than 50. 30-35 is often the ideal. 


@article{Laender:2002:BSW:565117.565137,
	author = {Laender, Alberto H. F. and Ribeiro-Neto, Berthier A. and da Silva, Altigran S. and Teixeira, Juliana S.},
	title = {A brief survey of web data extraction tools},
	journal = {SIGMOD Rec.},
	issue_date = {June 2002},
	volume = {31},
	number = {2},
	month = jun,
	year = {2002},
	issn = {0163-5808},
	pages = {84--93},
	numpages = {10},
	url = {http://doi.acm.org/10.1145/565117.565137},
	doi = {10.1145/565117.565137},
	acmid = {565137},
	publisher = {ACM},
	address = {new york, ny, usa},
} 

@article{Chang:2006:SWI:1159162.1159300,
	author = {Chang, Chia-Hui and Kayed, Mohammed and Girgis, Moheb Ramzy and Shaalan, Khaled F.},
	title = {A Survey of Web Information Extraction Systems},
	journal = {IEEE Trans. on Knowl. and Data Eng.},
	issue_date = {October 2006},
	volume = {18},
	number = {10},
	month = oct,
	year = {2006},
	issn = {1041-4347},
	pages = {1411--1428},
	numpages = {18},
	url = {http://dx.doi.org/10.1109/TKDE.2006.152},
	doi = {10.1109/TKDE.2006.152},
	acmid = {1159300},
	publisher = {IEEE Educational Activities Department},
	address = {Piscataway, NJ, USA},
	keywords = {Information extraction, Information extraction, Web mining, wrapper, wrapper induction., Web mining, wrapper, wrapper induction.},
} 

@inproceedings{Kowalkiewicz:2006:RWC:1135777.1135928,
	author = {Kowalkiewicz, Marek and Orlowska, Maria E. and Kaczmarek, Tomasz and Abramowicz, Witold},
	title = {Robust web content extraction},
	booktitle = {Proceedings of the 15th international conference on World Wide Web},
	series = {WWW '06},
	year = {2006},
	isbn = {1-59593-323-9},
	location = {Edinburgh, Scotland},
	pages = {887--888},
	numpages = {2},
	url = {http://doi.acm.org/10.1145/1135777.1135928},
	doi = {10.1145/1135777.1135928},
	acmid = {1135928},
	publisher = {ACM},
	address = {New York, NY, USA},
	keywords = {content extraction, evaluation, robustness, wrappers},
} 

@inproceedings{DBLP:conf/sigmod/DalviBS09,
  author    = {Nilesh N. Dalvi and
               Philip Bohannon and
               Fei Sha},
  title     = {Robust web extraction: an approach based on a probabilistic
               tree-edit model},
  booktitle = {SIGMOD Conference},
  year      = {2009},
  pages     = {335-348},
  ee        = {http://doi.acm.org/10.1145/1559845.1559882},
  crossref  = {DBLP:conf/sigmod/2009},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}

@article{DBLP:journals/pvldb/ParameswaranDGR11,
  author    = {Aditya G. Parameswaran and
               Nilesh N. Dalvi and
               Hector Garcia-Molina and
               Rajeev Rastogi},
  title     = {Optimal Schemes for Robust Web Extraction},
  journal   = {PVLDB},
  volume    = {4},
  number    = {11},
  year      = {2011},
  pages     = {980-991},
  ee        = {http://www.vldb.org/pvldb/vol4/p980-parameswaran.pdf},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}

@inproceedings{DBLP:conf/wism/LiuWYL12,
  author    = {Donglan Liu and
               Xinjun Wang and
               Zhongmin Yan and
               Qiuyan Li},
  title     = {Robust Web Data Extraction: A Novel Approach Based on Minimum
               Cost Script Edit Model},
  booktitle = {WISM},
  year      = {2012},
  pages     = {497-509},
  ee        = {http://dx.doi.org/10.1007/978-3-642-33469-6_62},
  crossref  = {DBLP:conf/wism/2012},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}

@article{Myllymaki02robustweb,
    author = {Jussi Myllymaki and Jared Jackson},
    title = {Robust Web Data Extraction with XML Path Expressions},
    journal = {IBM Research Report},
    year = {2002}
}

@inproceedings{DBLP:conf/icde/GulhaneMMRRSSTT11,
  author    = {Pankaj Gulhane and
               Amit Madaan and
               Rupesh R. Mehta and
               Jeyashankher Ramamirtham and
               Rajeev Rastogi and
               Sandeepkumar Satpal and
               Srinivasan H. Sengamedu and
               Ashwin Tengli and
               Charu Tiwari},
  title     = {Web-scale information extraction with vertex},
  booktitle = {ICDE},
  year      = {2011},
  pages     = {1209-1220},
  ee        = {http://doi.ieeecomputersociety.org/10.1109/ICDE.2011.5767842},
  crossref  = {DBLP:conf/icde/2011},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}

@inproceedings{Thomsen:2012:WWS:2364120.2364156,
 author = {Thomsen, Jakob G. and Ernst, Erik and Brabrand, Claus and Schwartzbach, Michael},
 title = {WebSelF: a web scraping framework},
 booktitle = {Proceedings of the 12th international conference on Web Engineering},
 series = {ICWE'12},
 year = {2012},
 isbn = {978-3-642-31752-1},
 location = {Berlin, Germany},
 pages = {347--361},
 numpages = {15},
 url = {http://dx.doi.org/10.1007/978-3-642-31753-8_28},
 doi = {10.1007/978-3-642-31753-8_28},
 acmid = {2364156},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
} 

@inproceedings{DBLP:conf/cikm/ZhengSWG09,
  author    = {Shuyi Zheng and
               Ruihua Song and
               Ji-Rong Wen and
               C. Lee Giles},
  title     = {Efficient record-level wrapper induction},
  booktitle = {CIKM},
  year      = {2009},
  pages     = {47-56},
  ee        = {http://doi.acm.org/10.1145/1645953.1645962},
  crossref  = {DBLP:conf/cikm/2009},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}

@proceedings{DBLP:conf/cikm/2009,
  editor    = {David Wai-Lok Cheung and
               Il-Yeol Song and
               Wesley W. Chu and
               Xiaohua Hu and
               Jimmy J. Lin},
  title     = {Proceedings of the 18th ACM Conference on Information and
               Knowledge Management, CIKM 2009, Hong Kong, China, November
               2-6, 2009},
  booktitle = {CIKM},
  publisher = {ACM},
  year      = {2009},
  isbn      = {978-1-60558-512-3},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}

@inproceedings{Chidlovskii:2006:DES:1142473.1142555,
 author = {Chidlovskii, Boris and Roustant, Bruno and Brette, Marc},
 title = {Documentum ECI Self-repairing Wrappers: Performance Analysis},
 booktitle = {Proceedings of the 2006 ACM SIGMOD International Conference on Management of Data},
 series = {SIGMOD '06},
 year = {2006},
 isbn = {1-59593-434-0},
 location = {Chicago, IL, USA},
 pages = {708--717},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1142473.1142555},
 doi = {10.1145/1142473.1142555},
 acmid = {1142555},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {content integration, web wrappers, wrapper maintenance},
} 

@article{signorini2005a,
  title = {The indexable web is more than 11.5 billion pages},
  publisher = {Association for Computing Machinery},
  author = {Signorini, A. and Gulli, A.},
  journal = {14th International World Wide Web Conference, WWW2005},
  pages = {902-903},
  year = {2005},
  isbn = {1595930515, 9781595930514},
  abstract = {In this short paper we estimate the size of the public indexable web at 11.5 billion pages. We also estimate the overlap and the index size of Google, MSN, Ask/Teoma and Yahoo!},
  doi = {10.1145/1062745.1062789}
}

@article{liu2009a,
  title = {Mining Data Records in Web Pages},
  language = {English},
  author = {Liu, Bing and Grossman, Robert and Zhai, Y.},
  year = {2009},
  abstract = {A large amount of information on the Web is contained in regularly structured objects, which we call data records. Such data records are important because they often present the essential information of their host pages, e.g., lists of products or services. It is useful to mine such data records in order to extract information from them to provide value-added services. Existing automatic techniques are not satisfactory because of their poor accuracies. In this paper, we propose a more effective technique to perform the task. The technique is based on two observations about data records on the Web and a string matching algorithm. The proposed technique is able to mine both contiguous and noncontiguous data records. Our experimental results show that the proposed technique outperforms existing techniques substantially. Categories and Subject Descriptors I.5 [Pattern Recognition]: statistical and structural H.2.8 [Database Applications]: data mining Keywords Web data records, Web mining, Web information integration 1.#}
}


@article{zhai2005a,
  title = {Web data extraction based on partial tree alignment},
  publisher = {ACM USA www.acm.org/publications},
  author = {Zhai, Yanhong and Liu, Bing},
  journal = {International World Wide Web Conference},
  pages = {76-85},
  year = {2005},
  isbn = {1595930469},
  abstract = {This paper studies the problem of extracting data from a Web page that contains several structured data records. The objective is to segment these data records, extract data items/fields from them and put the data in a database table. This problem has been studied by several researchers. However, existing methods still have some serious limitations. The first class of methods is based on machine learning, which requires human labeling of many examples from each Web site that one is interested in extracting data from. The process is time consuming due to the large number of sites and pages on the Web. The second class of algorithms is based on automatic pattern discovery. These methods are either inaccurate or make many assumptions. This paper proposes a new method to perform the task automatically. It consists of two steps, (1) identifying individual data records in a page, and (2) aligning and extracting data items from the identified data records. For step 1, we propose a method based on visual information to segment data records, which is more accurate than existing methods. For step 2, we propose a novel partial alignment technique based on tree matching. Partial alignment means that we align only those data fields in a pair of data records that can be aligned (or matched) with certainty, and make no commitment on the rest of the data fields. This approach enables very accurate alignment of multiple data records. Experimental results using a large number of Web pages from diverse domains show that the proposed two-step technique is able to segment data records, align and extract data from them very accurately.},
  doi = {10.1145/1060745.1060761}
}

@article{song2009a,
  title = {Efficient record-level wrapper induction},
  publisher = {Association for Computing Machinery},
  author = {Song, Ruihua and Wen, Ji Rong and Giles, C. Lee and Zheng, Shuyi},
  journal = {International Conference on Information and Knowledge Management, Proceedings},
  pages = {47-55},
  year = {2009},
  isbn = {9781605585123},
  abstract = {Web information is often presented in the form of record, e.g., a product record on a shopping website or a personal profile on a social utility website. Given a host webpage and related information needs, how to identify relevant records as well as their internal semantic structures is critical to many online information systems. Wrapper induction is one of the most effective methods for such tasks. However, most traditional wrapper techniques have issues dealing with web records since they are designed to extract information from a page, not a record. We propose a record-level wrapper system. In our system, we use a novel ''broom'' structure to represent both records and generated wrappers. With such representation, our system is able to effectively extract records and identify their internal semantics at the same time. We test our system on 16 real-life websites from four different domains. Experimental results demonstrate 99\% extraction accuracy in terms of F1-Value. Copyright 2009 ACM.},
  doi = {10.1145/1645953.1645962}
}



% examples

@webpage{TuringAward07,
   title         = {ACM Turing Award Honors Founders of Automatic Verification Technology},
   url           = {http://www.acm.org/press-room/news-releases-2008/turing-award-07},
   author        = {The Association for Computing Machinery},
   lastchecked   = {27-09-2010}
}

